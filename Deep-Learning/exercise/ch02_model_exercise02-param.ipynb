{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load digits dataset\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "Y_obj = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3071437902148591, 0.3766279093674481)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "np.mean(X_scaled), np.std(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_obj[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "Y = np_utils.to_categorical(Y_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련데이터셋 테스트데이터셋 (8:2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=3, n_neurons=64, learning_rate=3e-3,input_shape=[64]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "keras_clf = KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_clf.fit(X_train,y_train, epochs=2000,\n",
    "#              validation_split=0.2,\n",
    "#              callbacks=[keras.callbacks.EarlyStopping(patience=100)])\n",
    "# mse_test = keras_clf.score(X_test,y_test)\n",
    "# y_pred = keras_clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 766 samples, validate on 192 samples\n",
      "Epoch 1/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 6.0395 - accuracy: 0.1018 - val_loss: 5.0994 - val_accuracy: 0.0781\n",
      "Epoch 2/2000\n",
      "766/766 [==============================] - 1s 992us/step - loss: 4.5176 - accuracy: 0.1097 - val_loss: 12.5923 - val_accuracy: 0.0781\n",
      "Epoch 3/2000\n",
      "766/766 [==============================] - 1s 963us/step - loss: 4.3491 - accuracy: 0.1031 - val_loss: 2.3198 - val_accuracy: 0.1198\n",
      "Epoch 4/2000\n",
      "766/766 [==============================] - 1s 953us/step - loss: 2.3112 - accuracy: 0.0888 - val_loss: 2.3007 - val_accuracy: 0.1094\n",
      "Epoch 5/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3056 - accuracy: 0.0901 - val_loss: 2.3062 - val_accuracy: 0.1094\n",
      "Epoch 6/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3043 - accuracy: 0.0901 - val_loss: 2.3115 - val_accuracy: 0.1094\n",
      "Epoch 7/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3069 - accuracy: 0.0901 - val_loss: 2.3111 - val_accuracy: 0.1094\n",
      "Epoch 8/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 2.3055 - accuracy: 0.1136 - val_loss: 2.3068 - val_accuracy: 0.0990\n",
      "Epoch 9/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3052 - accuracy: 0.1005 - val_loss: 2.3118 - val_accuracy: 0.1302\n",
      "Epoch 10/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3061 - accuracy: 0.0953 - val_loss: 2.3051 - val_accuracy: 0.1094\n",
      "Epoch 11/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3072 - accuracy: 0.0901 - val_loss: 2.3137 - val_accuracy: 0.1094\n",
      "Epoch 12/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3048 - accuracy: 0.1005 - val_loss: 2.3082 - val_accuracy: 0.1198\n",
      "Epoch 13/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3059 - accuracy: 0.1057 - val_loss: 2.3060 - val_accuracy: 0.1094\n",
      "Epoch 14/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3051 - accuracy: 0.1031 - val_loss: 2.3085 - val_accuracy: 0.1094\n",
      "Epoch 15/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3063 - accuracy: 0.0901 - val_loss: 2.3080 - val_accuracy: 0.1094\n",
      "Epoch 16/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3296 - accuracy: 0.1240 - val_loss: 3.0492 - val_accuracy: 0.0521\n",
      "Epoch 17/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.4879 - accuracy: 0.0940 - val_loss: 2.3136 - val_accuracy: 0.1302\n",
      "Epoch 18/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3065 - accuracy: 0.0927 - val_loss: 2.3063 - val_accuracy: 0.1094\n",
      "Epoch 19/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3057 - accuracy: 0.0979 - val_loss: 2.3092 - val_accuracy: 0.1198\n",
      "Epoch 20/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3045 - accuracy: 0.1031 - val_loss: 2.3085 - val_accuracy: 0.1094\n",
      "Epoch 21/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 2.3045 - accuracy: 0.0901 - val_loss: 2.3112 - val_accuracy: 0.1094\n",
      "Epoch 22/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3057 - accuracy: 0.1005 - val_loss: 2.3105 - val_accuracy: 0.1094\n",
      "Epoch 23/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3065 - accuracy: 0.0901 - val_loss: 2.3093 - val_accuracy: 0.1094\n",
      "Epoch 24/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3044 - accuracy: 0.0979 - val_loss: 2.3140 - val_accuracy: 0.1198\n",
      "Epoch 25/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3060 - accuracy: 0.0979 - val_loss: 2.3067 - val_accuracy: 0.1094\n",
      "Epoch 26/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3074 - accuracy: 0.1136 - val_loss: 2.3087 - val_accuracy: 0.1198\n",
      "Epoch 27/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3053 - accuracy: 0.1188 - val_loss: 2.3081 - val_accuracy: 0.1094\n",
      "Epoch 28/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3047 - accuracy: 0.0901 - val_loss: 2.3135 - val_accuracy: 0.1094\n",
      "Epoch 29/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 2.3064 - accuracy: 0.0901 - val_loss: 2.3083 - val_accuracy: 0.1094\n",
      "Epoch 30/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 2.3052 - accuracy: 0.1057 - val_loss: 2.3080 - val_accuracy: 0.1302\n",
      "Epoch 31/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3040 - accuracy: 0.1005 - val_loss: 2.3154 - val_accuracy: 0.1198\n",
      "Epoch 32/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3054 - accuracy: 0.1110 - val_loss: 2.3060 - val_accuracy: 0.1094\n",
      "Epoch 33/2000\n",
      "766/766 [==============================] - 1s 1000us/step - loss: 2.3044 - accuracy: 0.0901 - val_loss: 2.3073 - val_accuracy: 0.1094\n",
      "Epoch 34/2000\n",
      "766/766 [==============================] - 1s 996us/step - loss: 2.2862 - accuracy: 0.0235 - val_loss: 2.2604 - val_accuracy: 0.0521\n",
      "Epoch 35/2000\n",
      "766/766 [==============================] - 1s 992us/step - loss: 4.5506 - accuracy: 0.0170 - val_loss: 2.2663 - val_accuracy: 0.0781\n",
      "Epoch 36/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.0434 - accuracy: 0.1828 - val_loss: 1.7897 - val_accuracy: 0.1719\n",
      "Epoch 37/2000\n",
      "766/766 [==============================] - 1s 992us/step - loss: 7.5026 - accuracy: 0.1305 - val_loss: 6.6319 - val_accuracy: 0.0781\n",
      "Epoch 38/2000\n",
      "766/766 [==============================] - 1s 985us/step - loss: 9.5320 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 39/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 40/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 41/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 42/2000\n",
      "766/766 [==============================] - 1s 987us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 43/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 44/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 45/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 46/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 47/2000\n",
      "766/766 [==============================] - 1s 995us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 48/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 49/2000\n",
      "766/766 [==============================] - 1s 992us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 50/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 51/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 52/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 53/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 54/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 55/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 56/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 1s 995us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 57/2000\n",
      "766/766 [==============================] - 1s 966us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 58/2000\n",
      "766/766 [==============================] - 1s 970us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 59/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 60/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 61/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 62/2000\n",
      "766/766 [==============================] - 1s 967us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 63/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 64/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 65/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 66/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 67/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 68/2000\n",
      "766/766 [==============================] - 1s 969us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 69/2000\n",
      "766/766 [==============================] - 1s 969us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 70/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 71/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 72/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 73/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 74/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 75/2000\n",
      "766/766 [==============================] - 1s 967us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 76/2000\n",
      "766/766 [==============================] - 1s 969us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 77/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 78/2000\n",
      "766/766 [==============================] - 1s 967us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 79/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 80/2000\n",
      "766/766 [==============================] - 1s 970us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 81/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 82/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 83/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 84/2000\n",
      "766/766 [==============================] - 1s 967us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 85/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 86/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 87/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 88/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 89/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 90/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 91/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 92/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 93/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 94/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 95/2000\n",
      "766/766 [==============================] - 1s 970us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 96/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 97/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 98/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 99/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 100/2000\n",
      "766/766 [==============================] - 1s 969us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 101/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 102/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 103/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 104/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 105/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 106/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 107/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 108/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 109/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 110/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 111/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 113/2000\n",
      "766/766 [==============================] - 1s 966us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 114/2000\n",
      "766/766 [==============================] - 1s 996us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 115/2000\n",
      "766/766 [==============================] - 1s 965us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 116/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 117/2000\n",
      "766/766 [==============================] - 1s 970us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 118/2000\n",
      "766/766 [==============================] - 1s 962us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 119/2000\n",
      "766/766 [==============================] - 1s 965us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 120/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 121/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 122/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 123/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 124/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 125/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 126/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 127/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 128/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 129/2000\n",
      "766/766 [==============================] - 1s 995us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 130/2000\n",
      "766/766 [==============================] - 1s 987us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 131/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 132/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 133/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 134/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 135/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "Epoch 136/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 9.6582 - accuracy: 0.1031 - val_loss: 9.4862 - val_accuracy: 0.0781\n",
      "479/479 [==============================] - 0s 125us/step\n",
      "Train on 766 samples, validate on 192 samples\n",
      "Epoch 1/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 3.7717 - accuracy: 0.0914 - val_loss: 9.4168 - val_accuracy: 0.1198\n",
      "Epoch 2/2000\n",
      "766/766 [==============================] - 1s 937us/step - loss: 2.7991 - accuracy: 0.0914 - val_loss: 2.3130 - val_accuracy: 0.0885\n",
      "Epoch 3/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3077 - accuracy: 0.1070 - val_loss: 2.3143 - val_accuracy: 0.0781\n",
      "Epoch 4/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3098 - accuracy: 0.0953 - val_loss: 2.3082 - val_accuracy: 0.0781\n",
      "Epoch 5/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3072 - accuracy: 0.1070 - val_loss: 2.3191 - val_accuracy: 0.0677\n",
      "Epoch 6/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3072 - accuracy: 0.0992 - val_loss: 2.3065 - val_accuracy: 0.0885\n",
      "Epoch 7/2000\n",
      "766/766 [==============================] - 1s 999us/step - loss: 2.3066 - accuracy: 0.0875 - val_loss: 2.3113 - val_accuracy: 0.0885\n",
      "Epoch 8/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3061 - accuracy: 0.1044 - val_loss: 2.3132 - val_accuracy: 0.0781\n",
      "Epoch 9/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3047 - accuracy: 0.1123 - val_loss: 2.3128 - val_accuracy: 0.0781\n",
      "Epoch 10/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3073 - accuracy: 0.0992 - val_loss: 2.3104 - val_accuracy: 0.0781\n",
      "Epoch 11/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3115 - accuracy: 0.0796 - val_loss: 2.3102 - val_accuracy: 0.0781\n",
      "Epoch 12/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3069 - accuracy: 0.0901 - val_loss: 2.3071 - val_accuracy: 0.0781\n",
      "Epoch 13/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 2.3067 - accuracy: 0.1044 - val_loss: 2.3114 - val_accuracy: 0.0781\n",
      "Epoch 14/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3077 - accuracy: 0.1123 - val_loss: 2.3148 - val_accuracy: 0.0781\n",
      "Epoch 15/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3037 - accuracy: 0.1123 - val_loss: 2.3138 - val_accuracy: 0.0781\n",
      "Epoch 16/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3065 - accuracy: 0.0914 - val_loss: 2.3051 - val_accuracy: 0.0781\n",
      "Epoch 17/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3087 - accuracy: 0.1123 - val_loss: 2.3176 - val_accuracy: 0.0781\n",
      "Epoch 18/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3050 - accuracy: 0.1123 - val_loss: 2.3118 - val_accuracy: 0.0781\n",
      "Epoch 19/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 2.3057 - accuracy: 0.0836 - val_loss: 2.3068 - val_accuracy: 0.0885\n",
      "Epoch 20/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3066 - accuracy: 0.0809 - val_loss: 2.3157 - val_accuracy: 0.0781\n",
      "Epoch 21/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3051 - accuracy: 0.1123 - val_loss: 2.3095 - val_accuracy: 0.0781\n",
      "Epoch 22/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3039 - accuracy: 0.1123 - val_loss: 2.3141 - val_accuracy: 0.0781\n",
      "Epoch 23/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3045 - accuracy: 0.1123 - val_loss: 2.3172 - val_accuracy: 0.0781\n",
      "Epoch 24/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3072 - accuracy: 0.1123 - val_loss: 2.3079 - val_accuracy: 0.0781\n",
      "Epoch 25/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3055 - accuracy: 0.1123 - val_loss: 2.3196 - val_accuracy: 0.0781\n",
      "Epoch 26/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3040 - accuracy: 0.0953 - val_loss: 2.3108 - val_accuracy: 0.0781\n",
      "Epoch 27/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3055 - accuracy: 0.1123 - val_loss: 2.3111 - val_accuracy: 0.0781\n",
      "Epoch 28/2000\n",
      "766/766 [==============================] - 1s 987us/step - loss: 2.3044 - accuracy: 0.1123 - val_loss: 2.3167 - val_accuracy: 0.0781\n",
      "Epoch 29/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3061 - accuracy: 0.1031 - val_loss: 2.3090 - val_accuracy: 0.0677\n",
      "Epoch 30/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 2.3049 - accuracy: 0.1031 - val_loss: 2.3134 - val_accuracy: 0.0781\n",
      "Epoch 31/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 1s 995us/step - loss: 2.3051 - accuracy: 0.1123 - val_loss: 2.3135 - val_accuracy: 0.0781\n",
      "Epoch 32/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3079 - accuracy: 0.0849 - val_loss: 2.3113 - val_accuracy: 0.0781\n",
      "Epoch 33/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3050 - accuracy: 0.1123 - val_loss: 2.3149 - val_accuracy: 0.0781\n",
      "Epoch 34/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3062 - accuracy: 0.1123 - val_loss: 2.3121 - val_accuracy: 0.0781\n",
      "Epoch 35/2000\n",
      "766/766 [==============================] - 1s 992us/step - loss: 2.3040 - accuracy: 0.1044 - val_loss: 2.3103 - val_accuracy: 0.0677\n",
      "Epoch 36/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3061 - accuracy: 0.1031 - val_loss: 2.3098 - val_accuracy: 0.0781\n",
      "Epoch 37/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 2.3035 - accuracy: 0.0992 - val_loss: 2.2838 - val_accuracy: 0.1927\n",
      "Epoch 38/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.6699 - accuracy: 0.1358 - val_loss: 2.3277 - val_accuracy: 0.0781\n",
      "Epoch 39/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3118 - accuracy: 0.0992 - val_loss: 2.3151 - val_accuracy: 0.0781\n",
      "Epoch 40/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3078 - accuracy: 0.0888 - val_loss: 2.3097 - val_accuracy: 0.0781\n",
      "Epoch 41/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3062 - accuracy: 0.1018 - val_loss: 2.3164 - val_accuracy: 0.0677\n",
      "Epoch 42/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3072 - accuracy: 0.1070 - val_loss: 2.3148 - val_accuracy: 0.0781\n",
      "Epoch 43/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3056 - accuracy: 0.1123 - val_loss: 2.3111 - val_accuracy: 0.0781\n",
      "Epoch 44/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 2.3059 - accuracy: 0.1031 - val_loss: 2.3136 - val_accuracy: 0.1302\n",
      "Epoch 45/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3040 - accuracy: 0.0940 - val_loss: 2.3098 - val_accuracy: 0.0781\n",
      "Epoch 46/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3044 - accuracy: 0.1123 - val_loss: 2.3134 - val_accuracy: 0.0781\n",
      "Epoch 47/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3098 - accuracy: 0.0862 - val_loss: 2.3169 - val_accuracy: 0.0781\n",
      "Epoch 48/2000\n",
      "766/766 [==============================] - 1s 971us/step - loss: 2.3051 - accuracy: 0.0849 - val_loss: 2.3120 - val_accuracy: 0.0781\n",
      "Epoch 49/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3049 - accuracy: 0.1123 - val_loss: 2.3133 - val_accuracy: 0.0781\n",
      "Epoch 50/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3061 - accuracy: 0.1057 - val_loss: 2.3086 - val_accuracy: 0.1302\n",
      "Epoch 51/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3085 - accuracy: 0.1018 - val_loss: 2.3181 - val_accuracy: 0.0885\n",
      "Epoch 52/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3079 - accuracy: 0.1097 - val_loss: 2.3123 - val_accuracy: 0.0781\n",
      "Epoch 53/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3034 - accuracy: 0.1123 - val_loss: 2.3132 - val_accuracy: 0.0781\n",
      "Epoch 54/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3049 - accuracy: 0.1123 - val_loss: 2.3093 - val_accuracy: 0.0781\n",
      "Epoch 55/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3055 - accuracy: 0.0979 - val_loss: 2.3124 - val_accuracy: 0.0885\n",
      "Epoch 56/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3056 - accuracy: 0.1031 - val_loss: 2.3128 - val_accuracy: 0.0781\n",
      "Epoch 57/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3061 - accuracy: 0.0875 - val_loss: 2.3112 - val_accuracy: 0.0885\n",
      "Epoch 58/2000\n",
      "766/766 [==============================] - 1s 970us/step - loss: 2.3092 - accuracy: 0.0888 - val_loss: 2.3133 - val_accuracy: 0.0781\n",
      "Epoch 59/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3045 - accuracy: 0.1123 - val_loss: 2.3150 - val_accuracy: 0.0781\n",
      "Epoch 60/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3048 - accuracy: 0.1018 - val_loss: 2.3119 - val_accuracy: 0.0885\n",
      "Epoch 61/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3048 - accuracy: 0.1044 - val_loss: 2.3083 - val_accuracy: 0.0781\n",
      "Epoch 62/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 2.3038 - accuracy: 0.0953 - val_loss: 2.3155 - val_accuracy: 0.0781\n",
      "Epoch 63/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3036 - accuracy: 0.1123 - val_loss: 2.3137 - val_accuracy: 0.0781\n",
      "Epoch 64/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3049 - accuracy: 0.1084 - val_loss: 2.3113 - val_accuracy: 0.0781\n",
      "Epoch 65/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3054 - accuracy: 0.1123 - val_loss: 2.3120 - val_accuracy: 0.0781\n",
      "Epoch 66/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3037 - accuracy: 0.1123 - val_loss: 2.3128 - val_accuracy: 0.0781\n",
      "Epoch 67/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3052 - accuracy: 0.1031 - val_loss: 2.3114 - val_accuracy: 0.0781\n",
      "Epoch 68/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3051 - accuracy: 0.1123 - val_loss: 2.3084 - val_accuracy: 0.0781\n",
      "Epoch 69/2000\n",
      "766/766 [==============================] - 1s 997us/step - loss: 2.3033 - accuracy: 0.1057 - val_loss: 2.3099 - val_accuracy: 0.0781\n",
      "Epoch 70/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3033 - accuracy: 0.1123 - val_loss: 2.3144 - val_accuracy: 0.0781\n",
      "Epoch 71/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 2.3045 - accuracy: 0.1123 - val_loss: 2.3077 - val_accuracy: 0.0781\n",
      "Epoch 72/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3040 - accuracy: 0.1123 - val_loss: 2.3143 - val_accuracy: 0.0781\n",
      "Epoch 73/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3048 - accuracy: 0.0992 - val_loss: 2.3104 - val_accuracy: 0.0781\n",
      "Epoch 74/2000\n",
      "766/766 [==============================] - 1s 999us/step - loss: 2.3042 - accuracy: 0.0953 - val_loss: 2.3115 - val_accuracy: 0.0885\n",
      "Epoch 75/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3046 - accuracy: 0.1136 - val_loss: 2.3092 - val_accuracy: 0.0781\n",
      "Epoch 76/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3039 - accuracy: 0.1123 - val_loss: 2.3135 - val_accuracy: 0.0781\n",
      "Epoch 77/2000\n",
      "766/766 [==============================] - 1s 996us/step - loss: 2.3046 - accuracy: 0.1123 - val_loss: 2.3112 - val_accuracy: 0.0781\n",
      "Epoch 78/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3040 - accuracy: 0.0940 - val_loss: 2.3132 - val_accuracy: 0.0781\n",
      "Epoch 79/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3044 - accuracy: 0.0927 - val_loss: 2.3102 - val_accuracy: 0.0781\n",
      "Epoch 80/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3056 - accuracy: 0.1123 - val_loss: 2.3101 - val_accuracy: 0.0781\n",
      "Epoch 81/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 2.3052 - accuracy: 0.1123 - val_loss: 2.3123 - val_accuracy: 0.0781\n",
      "Epoch 82/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3044 - accuracy: 0.1123 - val_loss: 2.3119 - val_accuracy: 0.0781\n",
      "Epoch 83/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3042 - accuracy: 0.1123 - val_loss: 2.3149 - val_accuracy: 0.0781\n",
      "Epoch 84/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3035 - accuracy: 0.0927 - val_loss: 2.3090 - val_accuracy: 0.0885\n",
      "Epoch 85/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 2.3032 - accuracy: 0.0953 - val_loss: 2.3136 - val_accuracy: 0.0781\n",
      "Epoch 86/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3050 - accuracy: 0.1123 - val_loss: 2.3107 - val_accuracy: 0.0781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3041 - accuracy: 0.1123 - val_loss: 2.3119 - val_accuracy: 0.0781\n",
      "Epoch 88/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3043 - accuracy: 0.1123 - val_loss: 2.3127 - val_accuracy: 0.0781\n",
      "Epoch 89/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3054 - accuracy: 0.0796 - val_loss: 2.3089 - val_accuracy: 0.0781\n",
      "Epoch 90/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 2.3035 - accuracy: 0.1123 - val_loss: 2.3118 - val_accuracy: 0.0781\n",
      "Epoch 91/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3051 - accuracy: 0.1044 - val_loss: 2.3116 - val_accuracy: 0.0781\n",
      "Epoch 92/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3032 - accuracy: 0.1123 - val_loss: 2.3127 - val_accuracy: 0.0781\n",
      "Epoch 93/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3039 - accuracy: 0.0914 - val_loss: 2.3148 - val_accuracy: 0.0781\n",
      "Epoch 94/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 2.3072 - accuracy: 0.0705 - val_loss: 2.3087 - val_accuracy: 0.0781\n",
      "Epoch 95/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3038 - accuracy: 0.1123 - val_loss: 2.3163 - val_accuracy: 0.0781\n",
      "Epoch 96/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3039 - accuracy: 0.1123 - val_loss: 2.3141 - val_accuracy: 0.0781\n",
      "Epoch 97/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 2.3035 - accuracy: 0.0992 - val_loss: 2.3102 - val_accuracy: 0.0781\n",
      "Epoch 98/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3034 - accuracy: 0.1123 - val_loss: 2.3115 - val_accuracy: 0.0781\n",
      "Epoch 99/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3038 - accuracy: 0.0914 - val_loss: 2.3111 - val_accuracy: 0.0885\n",
      "Epoch 100/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3069 - accuracy: 0.1110 - val_loss: 2.3146 - val_accuracy: 0.0781\n",
      "Epoch 101/2000\n",
      "766/766 [==============================] - 1s 970us/step - loss: 2.3053 - accuracy: 0.1005 - val_loss: 2.3091 - val_accuracy: 0.0885\n",
      "Epoch 102/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3038 - accuracy: 0.1084 - val_loss: 2.3156 - val_accuracy: 0.0781\n",
      "Epoch 103/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 2.3033 - accuracy: 0.1123 - val_loss: 2.3104 - val_accuracy: 0.0781\n",
      "Epoch 104/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3040 - accuracy: 0.1123 - val_loss: 2.3118 - val_accuracy: 0.0781\n",
      "Epoch 105/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3036 - accuracy: 0.1123 - val_loss: 2.3109 - val_accuracy: 0.0781\n",
      "Epoch 106/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 2.3032 - accuracy: 0.1123 - val_loss: 2.3128 - val_accuracy: 0.0781\n",
      "Epoch 107/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3033 - accuracy: 0.1123 - val_loss: 2.3121 - val_accuracy: 0.0781\n",
      "Epoch 108/2000\n",
      "766/766 [==============================] - ETA: 0s - loss: 2.3049 - accuracy: 0.11 - 1s 979us/step - loss: 2.3045 - accuracy: 0.1123 - val_loss: 2.3128 - val_accuracy: 0.0781\n",
      "Epoch 109/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 2.3032 - accuracy: 0.1123 - val_loss: 2.3096 - val_accuracy: 0.0781\n",
      "Epoch 110/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3041 - accuracy: 0.1031 - val_loss: 2.3129 - val_accuracy: 0.0781\n",
      "Epoch 111/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3033 - accuracy: 0.1123 - val_loss: 2.3126 - val_accuracy: 0.0781\n",
      "Epoch 112/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3032 - accuracy: 0.1123 - val_loss: 2.3128 - val_accuracy: 0.0781\n",
      "Epoch 113/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3042 - accuracy: 0.1123 - val_loss: 2.3141 - val_accuracy: 0.0781\n",
      "Epoch 114/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 2.3039 - accuracy: 0.1123 - val_loss: 2.3108 - val_accuracy: 0.0781\n",
      "Epoch 115/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 2.3033 - accuracy: 0.1123 - val_loss: 2.3100 - val_accuracy: 0.0781\n",
      "Epoch 116/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3033 - accuracy: 0.1123 - val_loss: 2.3140 - val_accuracy: 0.0781\n",
      "Epoch 117/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3051 - accuracy: 0.1123 - val_loss: 2.3100 - val_accuracy: 0.0781\n",
      "Epoch 118/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3039 - accuracy: 0.1123 - val_loss: 2.3125 - val_accuracy: 0.0781\n",
      "Epoch 119/2000\n",
      "766/766 [==============================] - 1s 993us/step - loss: 2.3047 - accuracy: 0.1123 - val_loss: 2.3104 - val_accuracy: 0.0781\n",
      "Epoch 120/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 2.3030 - accuracy: 0.1123 - val_loss: 2.3112 - val_accuracy: 0.0781\n",
      "Epoch 121/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3044 - accuracy: 0.1123 - val_loss: 2.3155 - val_accuracy: 0.0781\n",
      "Epoch 122/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 2.3050 - accuracy: 0.1031 - val_loss: 2.3120 - val_accuracy: 0.0781\n",
      "Epoch 123/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3027 - accuracy: 0.1123 - val_loss: 2.3087 - val_accuracy: 0.0781\n",
      "Epoch 124/2000\n",
      "766/766 [==============================] - 1s 992us/step - loss: 2.3039 - accuracy: 0.0992 - val_loss: 2.3108 - val_accuracy: 0.0781\n",
      "Epoch 125/2000\n",
      "766/766 [==============================] - 1s 987us/step - loss: 2.3040 - accuracy: 0.1123 - val_loss: 2.3128 - val_accuracy: 0.0781\n",
      "Epoch 126/2000\n",
      "766/766 [==============================] - 1s 977us/step - loss: 2.3038 - accuracy: 0.1123 - val_loss: 2.3121 - val_accuracy: 0.0781\n",
      "Epoch 127/2000\n",
      "766/766 [==============================] - 1s 982us/step - loss: 2.3034 - accuracy: 0.1123 - val_loss: 2.3107 - val_accuracy: 0.0781\n",
      "Epoch 128/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 2.3032 - accuracy: 0.1123 - val_loss: 2.3135 - val_accuracy: 0.0781\n",
      "Epoch 129/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 2.3044 - accuracy: 0.1123 - val_loss: 2.3127 - val_accuracy: 0.0781\n",
      "Epoch 130/2000\n",
      "766/766 [==============================] - 1s 999us/step - loss: 2.3044 - accuracy: 0.0966 - val_loss: 2.3102 - val_accuracy: 0.0781\n",
      "Epoch 131/2000\n",
      "766/766 [==============================] - 1s 970us/step - loss: 2.3044 - accuracy: 0.1123 - val_loss: 2.3087 - val_accuracy: 0.0781\n",
      "Epoch 132/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 2.3040 - accuracy: 0.0992 - val_loss: 2.3130 - val_accuracy: 0.0781\n",
      "Epoch 133/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 2.3036 - accuracy: 0.1123 - val_loss: 2.3091 - val_accuracy: 0.0781\n",
      "Epoch 134/2000\n",
      "766/766 [==============================] - 1s 975us/step - loss: 2.3035 - accuracy: 0.1123 - val_loss: 2.3153 - val_accuracy: 0.0781\n",
      "Epoch 135/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3035 - accuracy: 0.1123 - val_loss: 2.3135 - val_accuracy: 0.0781\n",
      "Epoch 136/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 2.3048 - accuracy: 0.1123 - val_loss: 2.3156 - val_accuracy: 0.0781\n",
      "Epoch 137/2000\n",
      "766/766 [==============================] - 1s 996us/step - loss: 2.3029 - accuracy: 0.1123 - val_loss: 2.3122 - val_accuracy: 0.0781\n",
      "479/479 [==============================] - 0s 115us/step\n",
      "Train on 766 samples, validate on 192 samples\n",
      "Epoch 1/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 8.9214 - accuracy: 0.0979 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 2/2000\n",
      "766/766 [==============================] - 1s 943us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 3/2000\n",
      "766/766 [==============================] - 1s 962us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 4/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 1s 979us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 5/2000\n",
      "766/766 [==============================] - 1s 995us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 6/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 7/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 8/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 9/2000\n",
      "766/766 [==============================] - 1s 987us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 10/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 11/2000\n",
      "766/766 [==============================] - 1s 997us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 12/2000\n",
      "766/766 [==============================] - 1s 990us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 13/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 14/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 15/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 16/2000\n",
      "766/766 [==============================] - 1s 976us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 17/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 18/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 19/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 20/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 21/2000\n",
      "766/766 [==============================] - 1s 996us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 22/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 23/2000\n",
      "766/766 [==============================] - 1s 995us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 24/2000\n",
      "766/766 [==============================] - 1s 978us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 25/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 26/2000\n",
      "766/766 [==============================] - 1s 986us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 27/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 28/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 29/2000\n",
      "766/766 [==============================] - 1s 988us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 30/2000\n",
      "766/766 [==============================] - 1s 980us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 31/2000\n",
      "766/766 [==============================] - 1s 991us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 32/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 33/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 34/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 35/2000\n",
      "766/766 [==============================] - 1s 987us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 36/2000\n",
      "766/766 [==============================] - 1s 974us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 37/2000\n",
      "766/766 [==============================] - 1s 984us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 38/2000\n",
      "766/766 [==============================] - 1s 997us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 39/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 40/2000\n",
      "766/766 [==============================] - 1s 973us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 41/2000\n",
      "766/766 [==============================] - 1s 979us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 42/2000\n",
      "766/766 [==============================] - 1s 983us/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 43/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 44/2000\n",
      "766/766 [==============================] - 1s 1ms/step - loss: 6.3126 - accuracy: 0.1005 - val_loss: 6.6319 - val_accuracy: 0.1250\n",
      "Epoch 45/2000\n",
      "608/766 [======================>.......] - ETA: 0s - loss: 6.2829 - accuracy: 0.0987"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ea14134e5307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=2000,\n\u001b[0;32m     13\u001b[0m                  \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                  callbacks=[early_stopping_callback])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1529\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 253\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import keras\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [3,4,5,6],\n",
    "    \"n_neurons\": np.arange(64,800),\n",
    "    \"learning_rate\": reciprocal(3e-4,3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=10,cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=2000,\n",
    "                 validation_split=0.2,\n",
    "                 callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test, y_test, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
