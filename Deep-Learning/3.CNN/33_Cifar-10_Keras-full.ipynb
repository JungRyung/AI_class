{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar-10 이미지 분류\n",
    "### 전체 데이터 사용\n",
    "### Data Augmentation 적용\n",
    "### 출처: [Achieving 90% accuracy in Object Recognition ](https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 자료형 변환 및 스케일링\n",
    "- X: 실수형으로 정규화\n",
    "- Y: 1-hot encoding\n",
    "    * airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) uint8\n",
      "(50000, 1) uint8\n",
      "(10000, 32, 32, 3) uint8\n",
      "(10000, 1) uint8\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train0), (X_test, y_test0) = cifar10.load_data()\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(y_train0.shape, y_train0.dtype)\n",
    "print(X_test.shape, X_test.dtype)\n",
    "print(y_test0.shape, y_test0.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) float32\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0\n",
    "\n",
    "print(X_train.shape, X_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(y_train0, 10)\n",
    "Y_test = tf.keras.utils.to_categorical(y_test0, 10)\n",
    "Y_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모형 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(weight_decay), \n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=RMSprop(lr=0.001, decay=weight_decay), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 30:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 40:\n",
    "        lrate = 0.0003\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to save checkpoint to use later\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "modelpath = \"model/Cifar-10-best.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-82535b37d4c0>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 1.8842 - accuracy: 0.4265\n",
      "Epoch 00001: val_loss improved from inf to 1.39975, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 1.8840 - accuracy: 0.4266 - val_loss: 1.3998 - val_accuracy: 0.5665 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.2502 - accuracy: 0.5913\n",
      "Epoch 00002: val_loss improved from 1.39975 to 1.29002, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 1.2502 - accuracy: 0.5913 - val_loss: 1.2900 - val_accuracy: 0.6069 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 1.0610 - accuracy: 0.6566\n",
      "Epoch 00003: val_loss improved from 1.29002 to 1.08945, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 1.0610 - accuracy: 0.6566 - val_loss: 1.0894 - val_accuracy: 0.6800 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.9571 - accuracy: 0.6937\n",
      "Epoch 00004: val_loss improved from 1.08945 to 0.97022, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.9568 - accuracy: 0.6938 - val_loss: 0.9702 - val_accuracy: 0.7046 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8927 - accuracy: 0.7199\n",
      "Epoch 00005: val_loss improved from 0.97022 to 0.93433, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.8927 - accuracy: 0.7199 - val_loss: 0.9343 - val_accuracy: 0.7181 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.8389 - accuracy: 0.7384\n",
      "Epoch 00006: val_loss improved from 0.93433 to 0.76732, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.8389 - accuracy: 0.7384 - val_loss: 0.7673 - val_accuracy: 0.7671 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.7986 - accuracy: 0.7517\n",
      "Epoch 00007: val_loss did not improve from 0.76732\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.7984 - accuracy: 0.7518 - val_loss: 0.7859 - val_accuracy: 0.7715 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.7657 - accuracy: 0.7638\n",
      "Epoch 00008: val_loss improved from 0.76732 to 0.75156, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.7655 - accuracy: 0.7639 - val_loss: 0.7516 - val_accuracy: 0.7775 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.7401 - accuracy: 0.7745\n",
      "Epoch 00009: val_loss did not improve from 0.75156\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.7399 - accuracy: 0.7745 - val_loss: 0.7555 - val_accuracy: 0.7748 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.7830\n",
      "Epoch 00010: val_loss did not improve from 0.75156\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.7145 - accuracy: 0.7830 - val_loss: 0.7665 - val_accuracy: 0.7746 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.7903\n",
      "Epoch 00011: val_loss improved from 0.75156 to 0.67525, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6985 - accuracy: 0.7903 - val_loss: 0.6752 - val_accuracy: 0.8035 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.6803 - accuracy: 0.7948\n",
      "Epoch 00012: val_loss did not improve from 0.67525\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6802 - accuracy: 0.7948 - val_loss: 0.7744 - val_accuracy: 0.7807 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.7991\n",
      "Epoch 00013: val_loss did not improve from 0.67525\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6683 - accuracy: 0.7991 - val_loss: 0.6964 - val_accuracy: 0.8047 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.6474 - accuracy: 0.8075\n",
      "Epoch 00014: val_loss improved from 0.67525 to 0.66918, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.6474 - accuracy: 0.8075 - val_loss: 0.6692 - val_accuracy: 0.8022 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6396 - accuracy: 0.8109\n",
      "Epoch 00015: val_loss did not improve from 0.66918\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6396 - accuracy: 0.8109 - val_loss: 0.6755 - val_accuracy: 0.8119 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.6238 - accuracy: 0.8149\n",
      "Epoch 00016: val_loss improved from 0.66918 to 0.61465, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6238 - accuracy: 0.8148 - val_loss: 0.6147 - val_accuracy: 0.8273 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.8186\n",
      "Epoch 00017: val_loss improved from 0.61465 to 0.60714, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6150 - accuracy: 0.8186 - val_loss: 0.6071 - val_accuracy: 0.8296 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.6088 - accuracy: 0.8200\n",
      "Epoch 00018: val_loss improved from 0.60714 to 0.57994, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.6089 - accuracy: 0.8199 - val_loss: 0.5799 - val_accuracy: 0.8389 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5987 - accuracy: 0.8233\n",
      "Epoch 00019: val_loss did not improve from 0.57994\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5987 - accuracy: 0.8233 - val_loss: 0.5937 - val_accuracy: 0.8331 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5830 - accuracy: 0.8294\n",
      "Epoch 00020: val_loss did not improve from 0.57994\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.5830 - accuracy: 0.8294 - val_loss: 0.5803 - val_accuracy: 0.8377 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5835 - accuracy: 0.8296\n",
      "Epoch 00021: val_loss did not improve from 0.57994\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.5835 - accuracy: 0.8296 - val_loss: 0.5834 - val_accuracy: 0.8372 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5779 - accuracy: 0.8311\n",
      "Epoch 00022: val_loss improved from 0.57994 to 0.56568, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5782 - accuracy: 0.8310 - val_loss: 0.5657 - val_accuracy: 0.8385 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5661 - accuracy: 0.8375\n",
      "Epoch 00023: val_loss improved from 0.56568 to 0.51279, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5661 - accuracy: 0.8375 - val_loss: 0.5128 - val_accuracy: 0.8596 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5624 - accuracy: 0.8383\n",
      "Epoch 00024: val_loss did not improve from 0.51279\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5624 - accuracy: 0.8383 - val_loss: 0.5564 - val_accuracy: 0.8438 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.8387\n",
      "Epoch 00025: val_loss did not improve from 0.51279\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5563 - accuracy: 0.8387 - val_loss: 0.5982 - val_accuracy: 0.8295 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5469 - accuracy: 0.8424\n",
      "Epoch 00026: val_loss did not improve from 0.51279\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.5472 - accuracy: 0.8423 - val_loss: 0.6205 - val_accuracy: 0.8247 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5491 - accuracy: 0.8410\n",
      "Epoch 00027: val_loss did not improve from 0.51279\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.5492 - accuracy: 0.8409 - val_loss: 0.5445 - val_accuracy: 0.8508 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.8464\n",
      "Epoch 00028: val_loss did not improve from 0.51279\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.5306 - accuracy: 0.8463 - val_loss: 0.5249 - val_accuracy: 0.8541 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.8467\n",
      "Epoch 00029: val_loss improved from 0.51279 to 0.50682, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 35s 44ms/step - loss: 0.5325 - accuracy: 0.8467 - val_loss: 0.5068 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.8496\n",
      "Epoch 00030: val_loss did not improve from 0.50682\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.5232 - accuracy: 0.8496 - val_loss: 0.5678 - val_accuracy: 0.8426 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5261 - accuracy: 0.8475\n",
      "Epoch 00031: val_loss did not improve from 0.50682\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.5261 - accuracy: 0.8476 - val_loss: 0.5126 - val_accuracy: 0.8578 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5006 - accuracy: 0.8576\n",
      "Epoch 00032: val_loss improved from 0.50682 to 0.49221, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.5006 - accuracy: 0.8576 - val_loss: 0.4922 - val_accuracy: 0.8646 - lr: 5.0000e-04\n",
      "Epoch 33/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8595\n",
      "Epoch 00033: val_loss did not improve from 0.49221\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.4941 - accuracy: 0.8595 - val_loss: 0.5284 - val_accuracy: 0.8558 - lr: 5.0000e-04\n",
      "Epoch 34/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.8627\n",
      "Epoch 00034: val_loss did not improve from 0.49221\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.4849 - accuracy: 0.8627 - val_loss: 0.5453 - val_accuracy: 0.8492 - lr: 5.0000e-04\n",
      "Epoch 35/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.8629\n",
      "Epoch 00035: val_loss did not improve from 0.49221\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.4831 - accuracy: 0.8629 - val_loss: 0.4925 - val_accuracy: 0.8684 - lr: 5.0000e-04\n",
      "Epoch 36/300\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.8646\n",
      "Epoch 00036: val_loss did not improve from 0.49221\n",
      "781/781 [==============================] - 34s 43ms/step - loss: 0.4769 - accuracy: 0.8646 - val_loss: 0.5028 - val_accuracy: 0.8625 - lr: 5.0000e-04\n",
      "Epoch 37/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.8626\n",
      "Epoch 00037: val_loss improved from 0.49221 to 0.48332, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 34s 44ms/step - loss: 0.4815 - accuracy: 0.8626 - val_loss: 0.4833 - val_accuracy: 0.8680 - lr: 5.0000e-04\n",
      "Epoch 38/300\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.8649\n",
      "Epoch 00038: val_loss improved from 0.48332 to 0.47138, saving model to model/Cifar-10-best.hdf5\n",
      "781/781 [==============================] - 35s 45ms/step - loss: 0.4768 - accuracy: 0.8649 - val_loss: 0.4714 - val_accuracy: 0.8708 - lr: 5.0000e-04\n",
      "Epoch 39/300\n",
      "649/781 [=======================>......] - ETA: 5s - loss: 0.4758 - accuracy: 0.8646"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-82535b37d4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=64),\n\u001b[0m\u001b[1;32m      4\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \"\"\"\n\u001b[1;32m   1464\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit_generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=64),\n",
    "                    steps_per_epoch=X_train.shape[0] // 64, epochs=300,\n",
    "                    verbose=1, validation_data=(X_test, Y_test),\n",
    "                    callbacks=[LearningRateScheduler(lr_schedule),checkpointer,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model\n",
    "model = load_model('model/Cifar-10-best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, batch_size=128, verbose=2)\n",
    "print('\\nAccuracy: %.4f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
